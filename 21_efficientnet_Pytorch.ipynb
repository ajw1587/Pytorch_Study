{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21_efficientnet_Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1Ylh7OkcHylQZHPT5pJ5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajw1587/Pytorch_Study/blob/main/21_efficientnet_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJIs9Pb7-VOl",
        "outputId": "d8d4c65e-e030-4ad4-bd53-b6688fea5b53"
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1kBMIhC-h9e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchsummary import summary"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntq7AiHsS-PQ"
      },
      "source": [
        "# Swish activation function\n",
        "class Swish(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x * self.sigmoid(x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2vKtlt1_DL1"
      },
      "source": [
        "# SE Block\n",
        "class SEBlock(nn.Module):\n",
        "  def __init__(self, in_channels, r = 4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.squeeze = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.excitation = nn.Sequential(\n",
        "        nn.Linear(in_channels, in_channels * r),\n",
        "        Swish(),\n",
        "        nn.Linear(in_channels * r, in_channels),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.squeeze(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.excitation(x)\n",
        "    x = x.view(x.size(0), x.size(1), 1, 1)\n",
        "    return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E00kWfqITjvp"
      },
      "source": [
        "class MBConv(nn.Module):\n",
        "  expand = 6\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride = 1, se_scale = 4, p = 0.5):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
        "\n",
        "    self.residual = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride = stride, padding = 0, bias = False),\n",
        "        nn.BatchNorm2d(in_channels * MBConv.expand, momentum = 0.99, eps = 1e-3),\n",
        "        Swish(),\n",
        "        nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size = kernel_size,\n",
        "                  stride = 1, padding = kernel_size // 2, bias = False, groups = in_channels * MBConv.expand),\n",
        "        nn.BatchNorm2d(in_channels * MBConv.expand, momentum = 0.99, eps = 1e-3),\n",
        "        Swish()\n",
        "    )\n",
        "\n",
        "    self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n",
        "\n",
        "    self.project = nn.Sequential(\n",
        "        nn.Conv2d(in_channels * MBConv.expand, out_channels, kernel_size = 1, stride = 1, padding = 0, bias = False),\n",
        "        nn.BatchNorm2d(out_channels, momentum = 0.99, eps = 1e-3)\n",
        "    )\n",
        "\n",
        "    self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.training:\n",
        "      if not torch.bernoulli(self.p):\n",
        "        return x\n",
        "\n",
        "    x_shortcut = x\n",
        "    x_residual = self.residual(x)\n",
        "    x_se = self.se(x_residual)\n",
        "\n",
        "    x = x_se * x_residual\n",
        "    x = self.project(x)\n",
        "\n",
        "    if self.shortcut:\n",
        "      x = x_shortcut + x\n",
        "\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMwYH_vV7fn"
      },
      "source": [
        "class SepConv(nn.Module):\n",
        "  expand = 1\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride = 1, se_scale = 4, p = 0.5):\n",
        "    super().__init__()\n",
        "    self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
        "\n",
        "    self.residual = nn.Sequential(\n",
        "        nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size = kernel_size,\n",
        "                  stride = 1, padding = kernel_size // 2, bias = False, groups = in_channels * SepConv.expand),\n",
        "        nn.BatchNorm2d(in_channels * SepConv.expand, momentum = 0.99, eps = 1e-3),\n",
        "        Swish()\n",
        "    )\n",
        "\n",
        "    self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n",
        "\n",
        "    self.project = nn.Sequential(\n",
        "        nn.Conv2d(in_channels * SepConv.expand, out_channels, kernel_size = 1, stride = 1, padding = 0, bias = False),\n",
        "        nn.BatchNorm2d(out_channels, momentum = 0.99, eps = 1e-3)\n",
        "    )\n",
        "\n",
        "    self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.training:\n",
        "      if not torch.bernoulli(self.p):\n",
        "        return x\n",
        "\n",
        "    x_shortcut = x\n",
        "    x_residual = self.residual(x)\n",
        "    x_se = self.se(x_residual)\n",
        "\n",
        "    x = x_se * x_residual\n",
        "    x = self.project(x)\n",
        "\n",
        "    if self.shortcut:\n",
        "      x = x_shortcut + x\n",
        "\n",
        "    return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx2OqYtQYDXi",
        "outputId": "3de2128c-833f-4e25-bbd7-799a772dee33"
      },
      "source": [
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=10, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n",
        "        super().__init__()\n",
        "        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
        "        repeats = [1, 2, 2, 3, 3, 4, 1]\n",
        "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
        "        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n",
        "        depth = depth_coef\n",
        "        width = width_coef\n",
        "\n",
        "        channels = [int(x*width) for x in channels]\n",
        "        repeats = [int(x*depth) for x in repeats]\n",
        "\n",
        "        # stochastic depth\n",
        "        if stochastic_depth:\n",
        "            self.p = p\n",
        "            self.step = (1 - 0.5) / (sum(repeats) - 1)\n",
        "        else:\n",
        "            self.p = 1\n",
        "            self.step = 0\n",
        "\n",
        "\n",
        "        # efficient net\n",
        "        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n",
        "\n",
        "        self.stage1 = nn.Sequential(\n",
        "            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n",
        "        )\n",
        "\n",
        "        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n",
        "\n",
        "        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n",
        "\n",
        "        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n",
        "\n",
        "        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n",
        "\n",
        "        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n",
        "\n",
        "        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n",
        "\n",
        "        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n",
        "\n",
        "        self.stage9 = nn.Sequential(\n",
        "            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n",
        "            Swish()\n",
        "        ) \n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.linear = nn.Linear(channels[8], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upsample(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.stage5(x)\n",
        "        x = self.stage6(x)\n",
        "        x = self.stage7(x)\n",
        "        x = self.stage8(x)\n",
        "        x = self.stage9(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n",
        "        strides = [stride] + [1] * (repeats - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n",
        "            in_channels = out_channels\n",
        "            self.p -= self.step\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def efficientnet_b0(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.0, scale=1.0,dropout=0.2, se_scale=4)\n",
        "\n",
        "def efficientnet_b1(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.1, scale=240/224, dropout=0.2, se_scale=4)\n",
        "\n",
        "def efficientnet_b2(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.1, depth_coef=1.2, scale=260/224., dropout=0.3, se_scale=4)\n",
        "\n",
        "def efficientnet_b3(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.2, depth_coef=1.4, scale=300/224, dropout=0.3, se_scale=4)\n",
        "\n",
        "def efficientnet_b4(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.4, depth_coef=1.8, scale=380/224, dropout=0.4, se_scale=4)\n",
        "\n",
        "def efficientnet_b5(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.6, depth_coef=2.2, scale=456/224, dropout=0.4, se_scale=4)\n",
        "\n",
        "def efficientnet_b6(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=1.8, depth_coef=2.6, scale=528/224, dropout=0.5, se_scale=4)\n",
        "\n",
        "def efficientnet_b7(num_classes=10):\n",
        "    return EfficientNet(num_classes=num_classes, width_coef=2.0, depth_coef=3.1, scale=600/224, dropout=0.5, se_scale=4)\n",
        "\n",
        "\n",
        "# check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "model = efficientnet_b0().to(device)\n",
        "output = model(x)\n",
        "print('output size:', output.size())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output size: torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGoN_m5pZBEh"
      },
      "source": [
        "# print model summary\n",
        "model = efficientnet_b0().to(device)\n",
        "summary(model, (3,224,224), device=device.type)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}